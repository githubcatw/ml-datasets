{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT2 techcrunch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/githubcatw/ml-datasets/blob/master/TechCrunch%20GPT2%20in%20Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GjvmYsUXKvc",
        "colab_type": "text"
      },
      "source": [
        "## Prereqs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySAUbQy8XDDM",
        "colab_type": "code",
        "outputId": "d7398eed-1bff-45c7-b703-318ba250351d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        }
      },
      "source": [
        "%%shell\n",
        "pip3 install gpt-2-simple\n",
        "wget https://raw.githubusercontent.com/githubcatw/ml-datasets/master/techcrunch.txt\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gpt-2-simple\n",
            "  Downloading https://files.pythonhosted.org/packages/ce/a9/e1545c0a96cfc5653ebb9e621cd00aca50ad0733a47e3f47ee211569fbd0/gpt_2_simple-0.5.4.tar.gz\n",
            "Collecting regex (from gpt-2-simple)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/4e/1b178c38c9a1a184288f72065a65ca01f3154df43c6ad898624149b8b4e0/regex-2019.06.08.tar.gz (651kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 11.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (1.16.4)\n",
            "Collecting toposort (from gpt-2-simple)\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/8a/321cd8ea5f4a22a06e3ba30ef31ec33bea11a3443eeb1d89807640ee6ed4/toposort-1.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (2019.6.16)\n",
            "Building wheels for collected packages: gpt-2-simple, regex\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpt-2-simple: filename=gpt_2_simple-0.5.4-cp36-none-any.whl size=25145 sha256=fdfd1dfc5194a6651050755afadb95e3d405cf424a5e26437120d836923826d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/39/91/667e099cf36dee458e2b5e39fc202da34d2c02b4005dd5dad3\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2019.6.8-cp36-cp36m-linux_x86_64.whl size=604144 sha256=81c35e2065334da097658590dc9b0e106d266029c4b4b2200ddae2e800af548d\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/e4/80/abf3b33ba89cf65cd262af8a22a5a999cc28fbfabea6b38473\n",
            "Successfully built gpt-2-simple regex\n",
            "Installing collected packages: regex, toposort, gpt-2-simple\n",
            "Successfully installed gpt-2-simple-0.5.4 regex-2019.6.8 toposort-1.5\n",
            "--2019-08-17 15:42:50--  https://raw.githubusercontent.com/githubcatw/ml-datasets/master/techcrunch.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23479 (23K) [text/plain]\n",
            "Saving to: ‘techcrunch.txt’\n",
            "\n",
            "techcrunch.txt      100%[===================>]  22.93K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2019-08-17 15:42:51 (3.32 MB/s) - ‘techcrunch.txt’ saved [23479/23479]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6P4CnjgPdpc",
        "colab_type": "text"
      },
      "source": [
        "## Actually finetune GPT2 on dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cawawwQJPkuG",
        "colab_type": "code",
        "outputId": "7c5c3108-0ada-4a38-ce40-dd2eb7943765",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "import gpt_2_simple as gpt2\n",
        "\n",
        "model_name = \"117M\"\n",
        "gpt2.download_gpt2(model_name=model_name)   # model is saved into current directory under /models/117M/\n",
        "\n",
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.finetune(sess,\n",
        "              'techcrunch.txt',\n",
        "              model_name=model_name,\n",
        "              steps=4000)   # steps is max number of training steps\n",
        "\n",
        "gpt2.generate(sess)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 220Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 70.7Mit/s]                                                   \n",
            "Fetching hparams.json: 1.05Mit [00:00, 157Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:02, 198Mit/s]                                   \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 282Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 117Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 109Mit/s]                                                       \n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0817 15:55:38.182279 140193927870336 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0817 15:55:58.221097 140193927870336 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint checkpoint/run1/model-1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1628.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n",
            "dataset has 5134 tokens\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[2 | 136.51] loss=3.48 avg=3.48\n",
            "[3 | 260.80] loss=3.30 avg=3.39\n",
            "[4 | 387.03] loss=3.29 avg=3.36\n",
            "[5 | 512.27] loss=3.13 avg=3.30\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}